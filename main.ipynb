{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from argparse import Namespace\n",
    "\n",
    "from loss import SIoULoss, YoloLoss\n",
    "\n",
    "classes_names = ['car', 'truck', 'pedestrian', 'bicyclist', 'light']\n",
    "S = 15\n",
    "C = len(classes_names)\n",
    "\n",
    "# Configuration\n",
    "cfg = Namespace(\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "\n",
    "  # Wandb\n",
    "  use_wandb = False,\n",
    "  project_name = 'Object detection testing',\n",
    "\n",
    "  # Dataset params\n",
    "  classes_names = classes_names,\n",
    "  S = S,\n",
    "  C = C,\n",
    "\n",
    "  # Data module params\n",
    "  batch_size = 32,\n",
    "  num_workers = 3,\n",
    "  pin_memory = torch.cuda.is_available(),\n",
    "\n",
    "  # Image resolution\n",
    "  image_width = 480,\n",
    "  image_height = 300,\n",
    "\n",
    "  # Training params\n",
    "  max_epochs = 5,\n",
    "  learning_rate = 1e-4,\n",
    "  weight_decay = 1e-4,\n",
    "  loss_fn = YoloLoss(C, nn.HuberLoss()),\n",
    "\n",
    "  # Model params\n",
    "  num_hidden = 2048,\n",
    "  chin = 3, \n",
    "  channels = 16,\n",
    "  max_grad_norm = 2.0,\n",
    "  dropout_rate = 0.15,\n",
    "  negative_slope = 0.01,\n",
    "\n",
    "  # Metrics params\n",
    "  iou_threshold = 0.5,\n",
    "  threshold = 0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.use_wandb:\n",
    "  !wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Training dataset shape:  (16012, 6)\n",
      "Validation dataset shape:  (4004, 6)\n",
      "Testing dataset shape:  (2225, 6)\n",
      "Dataset splitted (70%, 20%, 10%)!\n",
      "Creating model: \n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [32, 3, 480, 300]              84\n",
      "            Conv2d-2          [32, 1, 480, 300]               4\n",
      "       BatchNorm2d-3          [32, 1, 480, 300]               2\n",
      "         LeakyReLU-4          [32, 1, 480, 300]               0\n",
      "            Conv2d-5          [32, 3, 480, 300]              30\n",
      "       BatchNorm2d-6          [32, 3, 480, 300]               6\n",
      "         LeakyReLU-7          [32, 3, 480, 300]               0\n",
      "            Conv2d-8          [32, 3, 480, 300]              84\n",
      "            Conv2d-9          [32, 1, 480, 300]               4\n",
      "      BatchNorm2d-10          [32, 1, 480, 300]               2\n",
      "        LeakyReLU-11          [32, 1, 480, 300]               0\n",
      "           Conv2d-12          [32, 3, 480, 300]              30\n",
      "      BatchNorm2d-13          [32, 3, 480, 300]               6\n",
      "        LeakyReLU-14          [32, 3, 480, 300]               0\n",
      "           Conv2d-15          [32, 3, 480, 300]              84\n",
      "        LeakyReLU-16          [32, 3, 480, 300]               0\n",
      "      BatchNorm2d-17          [32, 3, 480, 300]               6\n",
      "        MaxPool2d-18          [32, 3, 240, 150]               0\n",
      "           Conv2d-19         [32, 16, 240, 150]             448\n",
      "      CustomBlock-20         [32, 16, 240, 150]               0\n",
      "           Conv2d-21         [32, 16, 240, 150]           2,320\n",
      "           Conv2d-22          [32, 8, 240, 150]             136\n",
      "      BatchNorm2d-23          [32, 8, 240, 150]              16\n",
      "        LeakyReLU-24          [32, 8, 240, 150]               0\n",
      "           Conv2d-25         [32, 16, 240, 150]           1,168\n",
      "      BatchNorm2d-26         [32, 16, 240, 150]              32\n",
      "        LeakyReLU-27         [32, 16, 240, 150]               0\n",
      "           Conv2d-28         [32, 16, 240, 150]           2,320\n",
      "           Conv2d-29          [32, 8, 240, 150]             136\n",
      "      BatchNorm2d-30          [32, 8, 240, 150]              16\n",
      "        LeakyReLU-31          [32, 8, 240, 150]               0\n",
      "           Conv2d-32         [32, 16, 240, 150]           1,168\n",
      "      BatchNorm2d-33         [32, 16, 240, 150]              32\n",
      "        LeakyReLU-34         [32, 16, 240, 150]               0\n",
      "           Conv2d-35         [32, 16, 240, 150]           2,320\n",
      "        LeakyReLU-36         [32, 16, 240, 150]               0\n",
      "      BatchNorm2d-37         [32, 16, 240, 150]              32\n",
      "        MaxPool2d-38          [32, 16, 120, 75]               0\n",
      "           Conv2d-39          [32, 32, 120, 75]           4,640\n",
      "      CustomBlock-40          [32, 32, 120, 75]               0\n",
      "           Conv2d-41          [32, 32, 120, 75]           9,248\n",
      "           Conv2d-42          [32, 16, 120, 75]             528\n",
      "      BatchNorm2d-43          [32, 16, 120, 75]              32\n",
      "        LeakyReLU-44          [32, 16, 120, 75]               0\n",
      "           Conv2d-45          [32, 32, 120, 75]           4,640\n",
      "      BatchNorm2d-46          [32, 32, 120, 75]              64\n",
      "        LeakyReLU-47          [32, 32, 120, 75]               0\n",
      "           Conv2d-48          [32, 32, 120, 75]           9,248\n",
      "           Conv2d-49          [32, 16, 120, 75]             528\n",
      "      BatchNorm2d-50          [32, 16, 120, 75]              32\n",
      "        LeakyReLU-51          [32, 16, 120, 75]               0\n",
      "           Conv2d-52          [32, 32, 120, 75]           4,640\n",
      "      BatchNorm2d-53          [32, 32, 120, 75]              64\n",
      "        LeakyReLU-54          [32, 32, 120, 75]               0\n",
      "           Conv2d-55          [32, 32, 120, 75]           9,248\n",
      "        LeakyReLU-56          [32, 32, 120, 75]               0\n",
      "      BatchNorm2d-57          [32, 32, 120, 75]              64\n",
      "        MaxPool2d-58           [32, 32, 60, 37]               0\n",
      "           Conv2d-59           [32, 64, 60, 37]          18,496\n",
      "      CustomBlock-60           [32, 64, 60, 37]               0\n",
      "           Conv2d-61           [32, 64, 60, 37]          36,928\n",
      "           Conv2d-62           [32, 32, 60, 37]           2,080\n",
      "      BatchNorm2d-63           [32, 32, 60, 37]              64\n",
      "        LeakyReLU-64           [32, 32, 60, 37]               0\n",
      "           Conv2d-65           [32, 64, 60, 37]          18,496\n",
      "      BatchNorm2d-66           [32, 64, 60, 37]             128\n",
      "        LeakyReLU-67           [32, 64, 60, 37]               0\n",
      "           Conv2d-68           [32, 64, 60, 37]          36,928\n",
      "           Conv2d-69           [32, 32, 60, 37]           2,080\n",
      "      BatchNorm2d-70           [32, 32, 60, 37]              64\n",
      "        LeakyReLU-71           [32, 32, 60, 37]               0\n",
      "           Conv2d-72           [32, 64, 60, 37]          18,496\n",
      "      BatchNorm2d-73           [32, 64, 60, 37]             128\n",
      "        LeakyReLU-74           [32, 64, 60, 37]               0\n",
      "           Conv2d-75           [32, 64, 60, 37]          36,928\n",
      "        LeakyReLU-76           [32, 64, 60, 37]               0\n",
      "      BatchNorm2d-77           [32, 64, 60, 37]             128\n",
      "        MaxPool2d-78           [32, 64, 30, 18]               0\n",
      "           Conv2d-79          [32, 128, 30, 18]          73,856\n",
      "      CustomBlock-80          [32, 128, 30, 18]               0\n",
      "           Conv2d-81          [32, 128, 30, 18]         147,584\n",
      "           Conv2d-82           [32, 64, 30, 18]           8,256\n",
      "      BatchNorm2d-83           [32, 64, 30, 18]             128\n",
      "        LeakyReLU-84           [32, 64, 30, 18]               0\n",
      "           Conv2d-85          [32, 128, 30, 18]          73,856\n",
      "      BatchNorm2d-86          [32, 128, 30, 18]             256\n",
      "        LeakyReLU-87          [32, 128, 30, 18]               0\n",
      "           Conv2d-88          [32, 128, 30, 18]         147,584\n",
      "           Conv2d-89           [32, 64, 30, 18]           8,256\n",
      "      BatchNorm2d-90           [32, 64, 30, 18]             128\n",
      "        LeakyReLU-91           [32, 64, 30, 18]               0\n",
      "           Conv2d-92          [32, 128, 30, 18]          73,856\n",
      "      BatchNorm2d-93          [32, 128, 30, 18]             256\n",
      "        LeakyReLU-94          [32, 128, 30, 18]               0\n",
      "           Conv2d-95          [32, 128, 30, 18]         147,584\n",
      "        LeakyReLU-96          [32, 128, 30, 18]               0\n",
      "      BatchNorm2d-97          [32, 128, 30, 18]             256\n",
      "        MaxPool2d-98           [32, 128, 15, 9]               0\n",
      "           Conv2d-99           [32, 256, 15, 9]         295,168\n",
      "     CustomBlock-100           [32, 256, 15, 9]               0\n",
      "          Conv2d-101           [32, 256, 15, 9]         590,080\n",
      "          Conv2d-102           [32, 128, 15, 9]          32,896\n",
      "     BatchNorm2d-103           [32, 128, 15, 9]             256\n",
      "       LeakyReLU-104           [32, 128, 15, 9]               0\n",
      "          Conv2d-105           [32, 256, 15, 9]         295,168\n",
      "     BatchNorm2d-106           [32, 256, 15, 9]             512\n",
      "       LeakyReLU-107           [32, 256, 15, 9]               0\n",
      "          Conv2d-108           [32, 256, 15, 9]         590,080\n",
      "          Conv2d-109           [32, 128, 15, 9]          32,896\n",
      "     BatchNorm2d-110           [32, 128, 15, 9]             256\n",
      "       LeakyReLU-111           [32, 128, 15, 9]               0\n",
      "          Conv2d-112           [32, 256, 15, 9]         295,168\n",
      "     BatchNorm2d-113           [32, 256, 15, 9]             512\n",
      "       LeakyReLU-114           [32, 256, 15, 9]               0\n",
      "          Conv2d-115           [32, 256, 15, 9]         590,080\n",
      "       LeakyReLU-116           [32, 256, 15, 9]               0\n",
      "     BatchNorm2d-117           [32, 256, 15, 9]             512\n",
      "       MaxPool2d-118            [32, 256, 7, 4]               0\n",
      "          Conv2d-119            [32, 512, 7, 4]       1,180,160\n",
      "     CustomBlock-120            [32, 512, 7, 4]               0\n",
      "          Conv2d-121            [32, 256, 7, 4]         131,072\n",
      "     BatchNorm2d-122            [32, 256, 7, 4]             512\n",
      "            SiLU-123            [32, 256, 7, 4]               0\n",
      "       MaxPool2d-124            [32, 256, 7, 4]               0\n",
      "       MaxPool2d-125            [32, 256, 7, 4]               0\n",
      "       MaxPool2d-126            [32, 256, 7, 4]               0\n",
      "          Conv2d-127            [32, 512, 7, 4]         524,288\n",
      "     BatchNorm2d-128            [32, 512, 7, 4]           1,024\n",
      "            SiLU-129            [32, 512, 7, 4]               0\n",
      "            SPPF-130            [32, 512, 7, 4]               0\n",
      "          Conv2d-131            [32, 256, 7, 4]         131,072\n",
      "     BatchNorm2d-132            [32, 256, 7, 4]             512\n",
      "            SiLU-133            [32, 256, 7, 4]               0\n",
      "             CBL-134            [32, 256, 7, 4]               0\n",
      "          Conv2d-135             [32, 64, 7, 4]          16,384\n",
      "     BatchNorm2d-136             [32, 64, 7, 4]             128\n",
      "            SiLU-137             [32, 64, 7, 4]               0\n",
      "             CBL-138             [32, 64, 7, 4]               0\n",
      "          Conv2d-139             [32, 64, 7, 4]           4,096\n",
      "     BatchNorm2d-140             [32, 64, 7, 4]             128\n",
      "            SiLU-141             [32, 64, 7, 4]               0\n",
      "             CBL-142             [32, 64, 7, 4]               0\n",
      "          Conv2d-143             [32, 64, 7, 4]          36,864\n",
      "     BatchNorm2d-144             [32, 64, 7, 4]             128\n",
      "            SiLU-145             [32, 64, 7, 4]               0\n",
      "             CBL-146             [32, 64, 7, 4]               0\n",
      "          Conv2d-147             [32, 64, 7, 4]           4,096\n",
      "     BatchNorm2d-148             [32, 64, 7, 4]             128\n",
      "            SiLU-149             [32, 64, 7, 4]               0\n",
      "             CBL-150             [32, 64, 7, 4]               0\n",
      "          Conv2d-151             [32, 64, 7, 4]          36,864\n",
      "     BatchNorm2d-152             [32, 64, 7, 4]             128\n",
      "            SiLU-153             [32, 64, 7, 4]               0\n",
      "             CBL-154             [32, 64, 7, 4]               0\n",
      "          Conv2d-155             [32, 64, 7, 4]          16,384\n",
      "     BatchNorm2d-156             [32, 64, 7, 4]             128\n",
      "            SiLU-157             [32, 64, 7, 4]               0\n",
      "             CBL-158             [32, 64, 7, 4]               0\n",
      "          Conv2d-159            [32, 128, 7, 4]          16,384\n",
      "     BatchNorm2d-160            [32, 128, 7, 4]             256\n",
      "            SiLU-161            [32, 128, 7, 4]               0\n",
      "             CBL-162            [32, 128, 7, 4]               0\n",
      "              C3-163            [32, 128, 7, 4]               0\n",
      "          Conv2d-164             [32, 64, 7, 4]           8,192\n",
      "     BatchNorm2d-165             [32, 64, 7, 4]             128\n",
      "            SiLU-166             [32, 64, 7, 4]               0\n",
      "             CBL-167             [32, 64, 7, 4]               0\n",
      "          Conv2d-168             [32, 32, 7, 4]           2,048\n",
      "     BatchNorm2d-169             [32, 32, 7, 4]              64\n",
      "            SiLU-170             [32, 32, 7, 4]               0\n",
      "             CBL-171             [32, 32, 7, 4]               0\n",
      "          Conv2d-172             [32, 32, 7, 4]           1,024\n",
      "     BatchNorm2d-173             [32, 32, 7, 4]              64\n",
      "            SiLU-174             [32, 32, 7, 4]               0\n",
      "             CBL-175             [32, 32, 7, 4]               0\n",
      "          Conv2d-176             [32, 32, 7, 4]           9,216\n",
      "     BatchNorm2d-177             [32, 32, 7, 4]              64\n",
      "            SiLU-178             [32, 32, 7, 4]               0\n",
      "             CBL-179             [32, 32, 7, 4]               0\n",
      "          Conv2d-180             [32, 32, 7, 4]           1,024\n",
      "     BatchNorm2d-181             [32, 32, 7, 4]              64\n",
      "            SiLU-182             [32, 32, 7, 4]               0\n",
      "             CBL-183             [32, 32, 7, 4]               0\n",
      "          Conv2d-184             [32, 32, 7, 4]           9,216\n",
      "     BatchNorm2d-185             [32, 32, 7, 4]              64\n",
      "            SiLU-186             [32, 32, 7, 4]               0\n",
      "             CBL-187             [32, 32, 7, 4]               0\n",
      "          Conv2d-188             [32, 32, 7, 4]           2,048\n",
      "     BatchNorm2d-189             [32, 32, 7, 4]              64\n",
      "            SiLU-190             [32, 32, 7, 4]               0\n",
      "             CBL-191             [32, 32, 7, 4]               0\n",
      "          Conv2d-192             [32, 64, 7, 4]           4,096\n",
      "     BatchNorm2d-193             [32, 64, 7, 4]             128\n",
      "            SiLU-194             [32, 64, 7, 4]               0\n",
      "             CBL-195             [32, 64, 7, 4]               0\n",
      "              C3-196             [32, 64, 7, 4]               0\n",
      "          Conv2d-197             [32, 64, 7, 4]          36,928\n",
      "          Conv2d-198             [32, 32, 7, 4]           2,080\n",
      "     BatchNorm2d-199             [32, 32, 7, 4]              64\n",
      "       LeakyReLU-200             [32, 32, 7, 4]               0\n",
      "          Conv2d-201             [32, 64, 7, 4]          18,496\n",
      "     BatchNorm2d-202             [32, 64, 7, 4]             128\n",
      "       LeakyReLU-203             [32, 64, 7, 4]               0\n",
      "          Conv2d-204             [32, 64, 7, 4]          36,928\n",
      "          Conv2d-205             [32, 32, 7, 4]           2,080\n",
      "     BatchNorm2d-206             [32, 32, 7, 4]              64\n",
      "       LeakyReLU-207             [32, 32, 7, 4]               0\n",
      "          Conv2d-208             [32, 64, 7, 4]          18,496\n",
      "     BatchNorm2d-209             [32, 64, 7, 4]             128\n",
      "       LeakyReLU-210             [32, 64, 7, 4]               0\n",
      "          Conv2d-211             [32, 64, 7, 4]          36,928\n",
      "       LeakyReLU-212             [32, 64, 7, 4]               0\n",
      "     BatchNorm2d-213             [32, 64, 7, 4]             128\n",
      "       MaxPool2d-214             [32, 64, 3, 2]               0\n",
      "          Conv2d-215            [32, 128, 3, 2]          73,856\n",
      "     CustomBlock-216            [32, 128, 3, 2]               0\n",
      "          Conv2d-217            [32, 128, 3, 2]         147,584\n",
      "          Conv2d-218             [32, 64, 3, 2]           8,256\n",
      "     BatchNorm2d-219             [32, 64, 3, 2]             128\n",
      "       LeakyReLU-220             [32, 64, 3, 2]               0\n",
      "          Conv2d-221            [32, 128, 3, 2]          73,856\n",
      "     BatchNorm2d-222            [32, 128, 3, 2]             256\n",
      "       LeakyReLU-223            [32, 128, 3, 2]               0\n",
      "          Conv2d-224            [32, 128, 3, 2]         147,584\n",
      "          Conv2d-225             [32, 64, 3, 2]           8,256\n",
      "     BatchNorm2d-226             [32, 64, 3, 2]             128\n",
      "       LeakyReLU-227             [32, 64, 3, 2]               0\n",
      "          Conv2d-228            [32, 128, 3, 2]          73,856\n",
      "     BatchNorm2d-229            [32, 128, 3, 2]             256\n",
      "       LeakyReLU-230            [32, 128, 3, 2]               0\n",
      "          Conv2d-231            [32, 128, 3, 2]         147,584\n",
      "       LeakyReLU-232            [32, 128, 3, 2]               0\n",
      "     BatchNorm2d-233            [32, 128, 3, 2]             256\n",
      "       MaxPool2d-234            [32, 128, 1, 1]               0\n",
      "          Conv2d-235            [32, 256, 1, 1]         295,168\n",
      "     CustomBlock-236            [32, 256, 1, 1]               0\n",
      "AdaptiveAvgPool2d-237            [32, 256, 1, 1]               0\n",
      "          Linear-238                 [32, 2048]         526,336\n",
      "       LeakyReLU-239                 [32, 2048]               0\n",
      "         Dropout-240                 [32, 2048]               0\n",
      "          Linear-241                 [32, 1024]       2,098,176\n",
      "       LeakyReLU-242                 [32, 1024]               0\n",
      "         Dropout-243                 [32, 1024]               0\n",
      "          Linear-244                 [32, 2250]       2,306,250\n",
      "         Sigmoid-245            [32, 15, 15, 2]               0\n",
      "================================================================\n",
      "Total params: 11,828,320\n",
      "Trainable params: 11,828,320\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 52.73\n",
      "Forward/backward pass size (MB): 5874.28\n",
      "Params size (MB): 45.12\n",
      "Estimated Total Size (MB): 5972.13\n",
      "----------------------------------------------------------------\n",
      "Epoch  0\n",
      "Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:44<00:00,  3.05it/s, avg_loss=3.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 3.3099992068227895\n",
      "Training R2 Score: 0.23250603675842285\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:37<00:00,  3.37it/s, avg_loss=2.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 2.904657318478539\n",
      "Validation R2 Score: 0.1305408477783203\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "Epoch  1\n",
      "Learning Rate: 9.045084971874738e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:43<00:00,  3.06it/s, avg_loss=2.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 2.178036239808667\n",
      "Training R2 Score: 0.23272866010665894\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:37<00:00,  3.37it/s, avg_loss=3.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 3.5352666094189598\n",
      "Validation R2 Score: -0.09440207481384277\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "Epoch  2\n",
      "Learning Rate: 6.545084971874737e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:44<00:00,  3.05it/s, avg_loss=2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 1.997513896928814\n",
      "Training R2 Score: 0.22996699810028076\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:37<00:00,  3.36it/s, avg_loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 2.2873234077105447\n",
      "Validation R2 Score: 0.2203262448310852\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "Epoch  3\n",
      "Learning Rate: 3.454915028125263e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:44<00:00,  3.05it/s, avg_loss=1.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 1.8786188889882285\n",
      "Training R2 Score: 0.226329505443573\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:37<00:00,  3.36it/s, avg_loss=2.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 2.347244961867257\n",
      "Validation R2 Score: 0.26795268058776855\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "Epoch  4\n",
      "Learning Rate: 9.549150281252631e-06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:43<00:00,  3.06it/s, avg_loss=1.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 1.7934603074829498\n",
      "Training R2 Score: 0.22545456886291504\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:37<00:00,  3.38it/s, avg_loss=2.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 2.3624649464137972\n",
      "Validation R2 Score: 0.25646281242370605\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 70/70 [00:24<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Average Loss: 2.351700690814427\n",
      "Testing R2 Score: 0.2463098168373108\n",
      "Testing Average mAP: 0.0\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Showing predictions on images!\n"
     ]
    }
   ],
   "source": [
    "from experiment import Experiment\n",
    "experiment = Experiment(cfg)\n",
    "experiment.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.loss_fn = YoloLoss(C, SIoULoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Training dataset shape:  (16012, 6)\n",
      "Validation dataset shape:  (4004, 6)\n",
      "Testing dataset shape:  (2225, 6)\n",
      "Dataset splitted (70%, 20%, 10%)!\n",
      "Creating model: \n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [32, 3, 480, 300]              84\n",
      "            Conv2d-2          [32, 1, 480, 300]               4\n",
      "       BatchNorm2d-3          [32, 1, 480, 300]               2\n",
      "         LeakyReLU-4          [32, 1, 480, 300]               0\n",
      "            Conv2d-5          [32, 3, 480, 300]              30\n",
      "       BatchNorm2d-6          [32, 3, 480, 300]               6\n",
      "         LeakyReLU-7          [32, 3, 480, 300]               0\n",
      "            Conv2d-8          [32, 3, 480, 300]              84\n",
      "            Conv2d-9          [32, 1, 480, 300]               4\n",
      "      BatchNorm2d-10          [32, 1, 480, 300]               2\n",
      "        LeakyReLU-11          [32, 1, 480, 300]               0\n",
      "           Conv2d-12          [32, 3, 480, 300]              30\n",
      "      BatchNorm2d-13          [32, 3, 480, 300]               6\n",
      "        LeakyReLU-14          [32, 3, 480, 300]               0\n",
      "           Conv2d-15          [32, 3, 480, 300]              84\n",
      "        LeakyReLU-16          [32, 3, 480, 300]               0\n",
      "      BatchNorm2d-17          [32, 3, 480, 300]               6\n",
      "        MaxPool2d-18          [32, 3, 240, 150]               0\n",
      "           Conv2d-19         [32, 16, 240, 150]             448\n",
      "      CustomBlock-20         [32, 16, 240, 150]               0\n",
      "           Conv2d-21         [32, 16, 240, 150]           2,320\n",
      "           Conv2d-22          [32, 8, 240, 150]             136\n",
      "      BatchNorm2d-23          [32, 8, 240, 150]              16\n",
      "        LeakyReLU-24          [32, 8, 240, 150]               0\n",
      "           Conv2d-25         [32, 16, 240, 150]           1,168\n",
      "      BatchNorm2d-26         [32, 16, 240, 150]              32\n",
      "        LeakyReLU-27         [32, 16, 240, 150]               0\n",
      "           Conv2d-28         [32, 16, 240, 150]           2,320\n",
      "           Conv2d-29          [32, 8, 240, 150]             136\n",
      "      BatchNorm2d-30          [32, 8, 240, 150]              16\n",
      "        LeakyReLU-31          [32, 8, 240, 150]               0\n",
      "           Conv2d-32         [32, 16, 240, 150]           1,168\n",
      "      BatchNorm2d-33         [32, 16, 240, 150]              32\n",
      "        LeakyReLU-34         [32, 16, 240, 150]               0\n",
      "           Conv2d-35         [32, 16, 240, 150]           2,320\n",
      "        LeakyReLU-36         [32, 16, 240, 150]               0\n",
      "      BatchNorm2d-37         [32, 16, 240, 150]              32\n",
      "        MaxPool2d-38          [32, 16, 120, 75]               0\n",
      "           Conv2d-39          [32, 32, 120, 75]           4,640\n",
      "      CustomBlock-40          [32, 32, 120, 75]               0\n",
      "           Conv2d-41          [32, 32, 120, 75]           9,248\n",
      "           Conv2d-42          [32, 16, 120, 75]             528\n",
      "      BatchNorm2d-43          [32, 16, 120, 75]              32\n",
      "        LeakyReLU-44          [32, 16, 120, 75]               0\n",
      "           Conv2d-45          [32, 32, 120, 75]           4,640\n",
      "      BatchNorm2d-46          [32, 32, 120, 75]              64\n",
      "        LeakyReLU-47          [32, 32, 120, 75]               0\n",
      "           Conv2d-48          [32, 32, 120, 75]           9,248\n",
      "           Conv2d-49          [32, 16, 120, 75]             528\n",
      "      BatchNorm2d-50          [32, 16, 120, 75]              32\n",
      "        LeakyReLU-51          [32, 16, 120, 75]               0\n",
      "           Conv2d-52          [32, 32, 120, 75]           4,640\n",
      "      BatchNorm2d-53          [32, 32, 120, 75]              64\n",
      "        LeakyReLU-54          [32, 32, 120, 75]               0\n",
      "           Conv2d-55          [32, 32, 120, 75]           9,248\n",
      "        LeakyReLU-56          [32, 32, 120, 75]               0\n",
      "      BatchNorm2d-57          [32, 32, 120, 75]              64\n",
      "        MaxPool2d-58           [32, 32, 60, 37]               0\n",
      "           Conv2d-59           [32, 64, 60, 37]          18,496\n",
      "      CustomBlock-60           [32, 64, 60, 37]               0\n",
      "           Conv2d-61           [32, 64, 60, 37]          36,928\n",
      "           Conv2d-62           [32, 32, 60, 37]           2,080\n",
      "      BatchNorm2d-63           [32, 32, 60, 37]              64\n",
      "        LeakyReLU-64           [32, 32, 60, 37]               0\n",
      "           Conv2d-65           [32, 64, 60, 37]          18,496\n",
      "      BatchNorm2d-66           [32, 64, 60, 37]             128\n",
      "        LeakyReLU-67           [32, 64, 60, 37]               0\n",
      "           Conv2d-68           [32, 64, 60, 37]          36,928\n",
      "           Conv2d-69           [32, 32, 60, 37]           2,080\n",
      "      BatchNorm2d-70           [32, 32, 60, 37]              64\n",
      "        LeakyReLU-71           [32, 32, 60, 37]               0\n",
      "           Conv2d-72           [32, 64, 60, 37]          18,496\n",
      "      BatchNorm2d-73           [32, 64, 60, 37]             128\n",
      "        LeakyReLU-74           [32, 64, 60, 37]               0\n",
      "           Conv2d-75           [32, 64, 60, 37]          36,928\n",
      "        LeakyReLU-76           [32, 64, 60, 37]               0\n",
      "      BatchNorm2d-77           [32, 64, 60, 37]             128\n",
      "        MaxPool2d-78           [32, 64, 30, 18]               0\n",
      "           Conv2d-79          [32, 128, 30, 18]          73,856\n",
      "      CustomBlock-80          [32, 128, 30, 18]               0\n",
      "           Conv2d-81          [32, 128, 30, 18]         147,584\n",
      "           Conv2d-82           [32, 64, 30, 18]           8,256\n",
      "      BatchNorm2d-83           [32, 64, 30, 18]             128\n",
      "        LeakyReLU-84           [32, 64, 30, 18]               0\n",
      "           Conv2d-85          [32, 128, 30, 18]          73,856\n",
      "      BatchNorm2d-86          [32, 128, 30, 18]             256\n",
      "        LeakyReLU-87          [32, 128, 30, 18]               0\n",
      "           Conv2d-88          [32, 128, 30, 18]         147,584\n",
      "           Conv2d-89           [32, 64, 30, 18]           8,256\n",
      "      BatchNorm2d-90           [32, 64, 30, 18]             128\n",
      "        LeakyReLU-91           [32, 64, 30, 18]               0\n",
      "           Conv2d-92          [32, 128, 30, 18]          73,856\n",
      "      BatchNorm2d-93          [32, 128, 30, 18]             256\n",
      "        LeakyReLU-94          [32, 128, 30, 18]               0\n",
      "           Conv2d-95          [32, 128, 30, 18]         147,584\n",
      "        LeakyReLU-96          [32, 128, 30, 18]               0\n",
      "      BatchNorm2d-97          [32, 128, 30, 18]             256\n",
      "        MaxPool2d-98           [32, 128, 15, 9]               0\n",
      "           Conv2d-99           [32, 256, 15, 9]         295,168\n",
      "     CustomBlock-100           [32, 256, 15, 9]               0\n",
      "          Conv2d-101           [32, 256, 15, 9]         590,080\n",
      "          Conv2d-102           [32, 128, 15, 9]          32,896\n",
      "     BatchNorm2d-103           [32, 128, 15, 9]             256\n",
      "       LeakyReLU-104           [32, 128, 15, 9]               0\n",
      "          Conv2d-105           [32, 256, 15, 9]         295,168\n",
      "     BatchNorm2d-106           [32, 256, 15, 9]             512\n",
      "       LeakyReLU-107           [32, 256, 15, 9]               0\n",
      "          Conv2d-108           [32, 256, 15, 9]         590,080\n",
      "          Conv2d-109           [32, 128, 15, 9]          32,896\n",
      "     BatchNorm2d-110           [32, 128, 15, 9]             256\n",
      "       LeakyReLU-111           [32, 128, 15, 9]               0\n",
      "          Conv2d-112           [32, 256, 15, 9]         295,168\n",
      "     BatchNorm2d-113           [32, 256, 15, 9]             512\n",
      "       LeakyReLU-114           [32, 256, 15, 9]               0\n",
      "          Conv2d-115           [32, 256, 15, 9]         590,080\n",
      "       LeakyReLU-116           [32, 256, 15, 9]               0\n",
      "     BatchNorm2d-117           [32, 256, 15, 9]             512\n",
      "       MaxPool2d-118            [32, 256, 7, 4]               0\n",
      "          Conv2d-119            [32, 512, 7, 4]       1,180,160\n",
      "     CustomBlock-120            [32, 512, 7, 4]               0\n",
      "          Conv2d-121            [32, 256, 7, 4]         131,072\n",
      "     BatchNorm2d-122            [32, 256, 7, 4]             512\n",
      "            SiLU-123            [32, 256, 7, 4]               0\n",
      "       MaxPool2d-124            [32, 256, 7, 4]               0\n",
      "       MaxPool2d-125            [32, 256, 7, 4]               0\n",
      "       MaxPool2d-126            [32, 256, 7, 4]               0\n",
      "          Conv2d-127            [32, 512, 7, 4]         524,288\n",
      "     BatchNorm2d-128            [32, 512, 7, 4]           1,024\n",
      "            SiLU-129            [32, 512, 7, 4]               0\n",
      "            SPPF-130            [32, 512, 7, 4]               0\n",
      "          Conv2d-131            [32, 256, 7, 4]         131,072\n",
      "     BatchNorm2d-132            [32, 256, 7, 4]             512\n",
      "            SiLU-133            [32, 256, 7, 4]               0\n",
      "             CBL-134            [32, 256, 7, 4]               0\n",
      "          Conv2d-135             [32, 64, 7, 4]          16,384\n",
      "     BatchNorm2d-136             [32, 64, 7, 4]             128\n",
      "            SiLU-137             [32, 64, 7, 4]               0\n",
      "             CBL-138             [32, 64, 7, 4]               0\n",
      "          Conv2d-139             [32, 64, 7, 4]           4,096\n",
      "     BatchNorm2d-140             [32, 64, 7, 4]             128\n",
      "            SiLU-141             [32, 64, 7, 4]               0\n",
      "             CBL-142             [32, 64, 7, 4]               0\n",
      "          Conv2d-143             [32, 64, 7, 4]          36,864\n",
      "     BatchNorm2d-144             [32, 64, 7, 4]             128\n",
      "            SiLU-145             [32, 64, 7, 4]               0\n",
      "             CBL-146             [32, 64, 7, 4]               0\n",
      "          Conv2d-147             [32, 64, 7, 4]           4,096\n",
      "     BatchNorm2d-148             [32, 64, 7, 4]             128\n",
      "            SiLU-149             [32, 64, 7, 4]               0\n",
      "             CBL-150             [32, 64, 7, 4]               0\n",
      "          Conv2d-151             [32, 64, 7, 4]          36,864\n",
      "     BatchNorm2d-152             [32, 64, 7, 4]             128\n",
      "            SiLU-153             [32, 64, 7, 4]               0\n",
      "             CBL-154             [32, 64, 7, 4]               0\n",
      "          Conv2d-155             [32, 64, 7, 4]          16,384\n",
      "     BatchNorm2d-156             [32, 64, 7, 4]             128\n",
      "            SiLU-157             [32, 64, 7, 4]               0\n",
      "             CBL-158             [32, 64, 7, 4]               0\n",
      "          Conv2d-159            [32, 128, 7, 4]          16,384\n",
      "     BatchNorm2d-160            [32, 128, 7, 4]             256\n",
      "            SiLU-161            [32, 128, 7, 4]               0\n",
      "             CBL-162            [32, 128, 7, 4]               0\n",
      "              C3-163            [32, 128, 7, 4]               0\n",
      "          Conv2d-164             [32, 64, 7, 4]           8,192\n",
      "     BatchNorm2d-165             [32, 64, 7, 4]             128\n",
      "            SiLU-166             [32, 64, 7, 4]               0\n",
      "             CBL-167             [32, 64, 7, 4]               0\n",
      "          Conv2d-168             [32, 32, 7, 4]           2,048\n",
      "     BatchNorm2d-169             [32, 32, 7, 4]              64\n",
      "            SiLU-170             [32, 32, 7, 4]               0\n",
      "             CBL-171             [32, 32, 7, 4]               0\n",
      "          Conv2d-172             [32, 32, 7, 4]           1,024\n",
      "     BatchNorm2d-173             [32, 32, 7, 4]              64\n",
      "            SiLU-174             [32, 32, 7, 4]               0\n",
      "             CBL-175             [32, 32, 7, 4]               0\n",
      "          Conv2d-176             [32, 32, 7, 4]           9,216\n",
      "     BatchNorm2d-177             [32, 32, 7, 4]              64\n",
      "            SiLU-178             [32, 32, 7, 4]               0\n",
      "             CBL-179             [32, 32, 7, 4]               0\n",
      "          Conv2d-180             [32, 32, 7, 4]           1,024\n",
      "     BatchNorm2d-181             [32, 32, 7, 4]              64\n",
      "            SiLU-182             [32, 32, 7, 4]               0\n",
      "             CBL-183             [32, 32, 7, 4]               0\n",
      "          Conv2d-184             [32, 32, 7, 4]           9,216\n",
      "     BatchNorm2d-185             [32, 32, 7, 4]              64\n",
      "            SiLU-186             [32, 32, 7, 4]               0\n",
      "             CBL-187             [32, 32, 7, 4]               0\n",
      "          Conv2d-188             [32, 32, 7, 4]           2,048\n",
      "     BatchNorm2d-189             [32, 32, 7, 4]              64\n",
      "            SiLU-190             [32, 32, 7, 4]               0\n",
      "             CBL-191             [32, 32, 7, 4]               0\n",
      "          Conv2d-192             [32, 64, 7, 4]           4,096\n",
      "     BatchNorm2d-193             [32, 64, 7, 4]             128\n",
      "            SiLU-194             [32, 64, 7, 4]               0\n",
      "             CBL-195             [32, 64, 7, 4]               0\n",
      "              C3-196             [32, 64, 7, 4]               0\n",
      "          Conv2d-197             [32, 64, 7, 4]          36,928\n",
      "          Conv2d-198             [32, 32, 7, 4]           2,080\n",
      "     BatchNorm2d-199             [32, 32, 7, 4]              64\n",
      "       LeakyReLU-200             [32, 32, 7, 4]               0\n",
      "          Conv2d-201             [32, 64, 7, 4]          18,496\n",
      "     BatchNorm2d-202             [32, 64, 7, 4]             128\n",
      "       LeakyReLU-203             [32, 64, 7, 4]               0\n",
      "          Conv2d-204             [32, 64, 7, 4]          36,928\n",
      "          Conv2d-205             [32, 32, 7, 4]           2,080\n",
      "     BatchNorm2d-206             [32, 32, 7, 4]              64\n",
      "       LeakyReLU-207             [32, 32, 7, 4]               0\n",
      "          Conv2d-208             [32, 64, 7, 4]          18,496\n",
      "     BatchNorm2d-209             [32, 64, 7, 4]             128\n",
      "       LeakyReLU-210             [32, 64, 7, 4]               0\n",
      "          Conv2d-211             [32, 64, 7, 4]          36,928\n",
      "       LeakyReLU-212             [32, 64, 7, 4]               0\n",
      "     BatchNorm2d-213             [32, 64, 7, 4]             128\n",
      "       MaxPool2d-214             [32, 64, 3, 2]               0\n",
      "          Conv2d-215            [32, 128, 3, 2]          73,856\n",
      "     CustomBlock-216            [32, 128, 3, 2]               0\n",
      "          Conv2d-217            [32, 128, 3, 2]         147,584\n",
      "          Conv2d-218             [32, 64, 3, 2]           8,256\n",
      "     BatchNorm2d-219             [32, 64, 3, 2]             128\n",
      "       LeakyReLU-220             [32, 64, 3, 2]               0\n",
      "          Conv2d-221            [32, 128, 3, 2]          73,856\n",
      "     BatchNorm2d-222            [32, 128, 3, 2]             256\n",
      "       LeakyReLU-223            [32, 128, 3, 2]               0\n",
      "          Conv2d-224            [32, 128, 3, 2]         147,584\n",
      "          Conv2d-225             [32, 64, 3, 2]           8,256\n",
      "     BatchNorm2d-226             [32, 64, 3, 2]             128\n",
      "       LeakyReLU-227             [32, 64, 3, 2]               0\n",
      "          Conv2d-228            [32, 128, 3, 2]          73,856\n",
      "     BatchNorm2d-229            [32, 128, 3, 2]             256\n",
      "       LeakyReLU-230            [32, 128, 3, 2]               0\n",
      "          Conv2d-231            [32, 128, 3, 2]         147,584\n",
      "       LeakyReLU-232            [32, 128, 3, 2]               0\n",
      "     BatchNorm2d-233            [32, 128, 3, 2]             256\n",
      "       MaxPool2d-234            [32, 128, 1, 1]               0\n",
      "          Conv2d-235            [32, 256, 1, 1]         295,168\n",
      "     CustomBlock-236            [32, 256, 1, 1]               0\n",
      "AdaptiveAvgPool2d-237            [32, 256, 1, 1]               0\n",
      "          Linear-238                 [32, 2048]         526,336\n",
      "       LeakyReLU-239                 [32, 2048]               0\n",
      "         Dropout-240                 [32, 2048]               0\n",
      "          Linear-241                 [32, 1024]       2,098,176\n",
      "       LeakyReLU-242                 [32, 1024]               0\n",
      "         Dropout-243                 [32, 1024]               0\n",
      "          Linear-244                 [32, 2250]       2,306,250\n",
      "         Sigmoid-245            [32, 15, 15, 2]               0\n",
      "================================================================\n",
      "Total params: 11,828,320\n",
      "Trainable params: 11,828,320\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 52.73\n",
      "Forward/backward pass size (MB): 5874.28\n",
      "Params size (MB): 45.12\n",
      "Estimated Total Size (MB): 5972.13\n",
      "----------------------------------------------------------------\n",
      "Epoch  0\n",
      "Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:50<00:00,  2.94it/s, avg_loss=3.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 3.8082425544956724\n",
      "Training R2 Score: 0.09792804718017578\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:38<00:00,  3.30it/s, avg_loss=2.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 2.043501445225307\n",
      "Validation R2 Score: 0.26587891578674316\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "Epoch  1\n",
      "Learning Rate: 9.045084971874738e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:50<00:00,  2.93it/s, avg_loss=2.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 2.0754906579168018\n",
      "Training R2 Score: 0.24280357360839844\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:38<00:00,  3.29it/s, avg_loss=2.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 2.1004975527998\n",
      "Validation R2 Score: 0.27101898193359375\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "Epoch  2\n",
      "Learning Rate: 6.545084971874737e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:50<00:00,  2.93it/s, avg_loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 1.8888620417751\n",
      "Training R2 Score: 0.2619549632072449\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:38<00:00,  3.31it/s, avg_loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 1.927946743984071\n",
      "Validation R2 Score: 0.29358500242233276\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "Epoch  3\n",
      "Learning Rate: 3.454915028125263e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:50<00:00,  2.94it/s, avg_loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 1.7505100759679448\n",
      "Training R2 Score: 0.2970859408378601\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:38<00:00,  3.29it/s, avg_loss=2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 1.997511347134908\n",
      "Validation R2 Score: 0.2957189679145813\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "Epoch  4\n",
      "Learning Rate: 9.549150281252631e-06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 501/501 [02:50<00:00,  2.93it/s, avg_loss=1.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Average Loss: 1.7212811257548912\n",
      "Training R2 Score: 0.3078538179397583\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 126/126 [00:38<00:00,  3.30it/s, avg_loss=1.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Average Loss: 1.9417071427617754\n",
      "Validation R2 Score: 0.30450767278671265\n",
      "Validation Average mAP: 0.0\n",
      "-------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 70/70 [00:24<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Average Loss: 1.9415004253387451\n",
      "Testing R2 Score: 0.301516056060791\n",
      "Testing Average mAP: 0.0\n",
      "\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Showing predictions on images!\n"
     ]
    }
   ],
   "source": [
    "from experiment import Experiment\n",
    "experiment = Experiment(cfg)\n",
    "experiment.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
